# å¼€å‘è€…è´¡çŒ®æŒ‡å—

æ„Ÿè°¢æ‚¨å¯¹å¤šLLMæ¨¡å‹æ¯”è¾ƒå™¨é¡¹ç›®çš„å…³æ³¨ï¼æœ¬æ–‡æ¡£å°†æŒ‡å¯¼æ‚¨å¦‚ä½•ä¸ºé¡¹ç›®åšå‡ºè´¡çŒ®ã€‚

## å¼€å‘ç¯å¢ƒè®¾ç½®

### å‰ç½®è¦æ±‚

- Python 3.12+
- uvåŒ…ç®¡ç†å™¨
- Git
- æ¨èï¼šVS Codeæˆ–PyCharm

### ç¯å¢ƒé…ç½®

1. **Forkå¹¶å…‹éš†é¡¹ç›®**
```bash
git clone https://github.com/your-username/multi-llm-comparator.git
cd multi-llm-comparator
```

2. **è®¾ç½®å¼€å‘ç¯å¢ƒ**
```bash
# å®‰è£…uvï¼ˆå¦‚æœå°šæœªå®‰è£…ï¼‰
curl -LsSf https://astral.sh/uv/install.sh | sh

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ–
uv sync --dev

# å®‰è£…pre-commité’©å­
uv run pre-commit install
```

3. **éªŒè¯å®‰è£…**
```bash
# è¿è¡Œæµ‹è¯•
uv run pytest

# æ£€æŸ¥ä»£ç æ ¼å¼
uv run black --check src/ tests/
uv run ruff check src/ tests/

# å¯åŠ¨åº”ç”¨
uv run streamlit run src/multi_llm_comparator/main.py
```

## å¼€å‘å·¥ä½œæµ

### åˆ†æ”¯ç­–ç•¥

- `main`: ä¸»åˆ†æ”¯ï¼ŒåŒ…å«ç¨³å®šçš„ç”Ÿäº§ä»£ç 
- `develop`: å¼€å‘åˆ†æ”¯ï¼ŒåŒ…å«æœ€æ–°çš„å¼€å‘ä»£ç 
- `feature/*`: åŠŸèƒ½åˆ†æ”¯ï¼Œç”¨äºå¼€å‘æ–°åŠŸèƒ½
- `bugfix/*`: ä¿®å¤åˆ†æ”¯ï¼Œç”¨äºä¿®å¤bug
- `hotfix/*`: çƒ­ä¿®å¤åˆ†æ”¯ï¼Œç”¨äºç´§æ€¥ä¿®å¤

### å¼€å‘æµç¨‹

1. **åˆ›å»ºåŠŸèƒ½åˆ†æ”¯**
```bash
git checkout develop
git pull origin develop
git checkout -b feature/your-feature-name
```

2. **å¼€å‘å’Œæµ‹è¯•**
```bash
# ç¼–å†™ä»£ç 
# è¿è¡Œæµ‹è¯•
uv run pytest tests/

# æ£€æŸ¥ä»£ç è´¨é‡
uv run black src/ tests/
uv run ruff check src/ tests/
uv run mypy src/
```

3. **æäº¤ä»£ç **
```bash
git add .
git commit -m "feat: add your feature description"
```

4. **æ¨é€å¹¶åˆ›å»ºPR**
```bash
git push origin feature/your-feature-name
# åœ¨GitHubä¸Šåˆ›å»ºPull Request
```

## ä»£ç è§„èŒƒ

### Pythonä»£ç é£æ ¼

æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹å·¥å…·ç¡®ä¿ä»£ç è´¨é‡ï¼š

- **Black**: ä»£ç æ ¼å¼åŒ–
- **Ruff**: ä»£ç æ£€æŸ¥å’Œå¯¼å…¥æ’åº
- **MyPy**: ç±»å‹æ£€æŸ¥
- **Pytest**: å•å…ƒæµ‹è¯•

### ä»£ç æ ¼å¼åŒ–

```bash
# è‡ªåŠ¨æ ¼å¼åŒ–ä»£ç 
uv run black src/ tests/

# æ£€æŸ¥æ ¼å¼
uv run black --check src/ tests/

# ä¿®å¤å¯¼å…¥å’Œä»£ç é—®é¢˜
uv run ruff check --fix src/ tests/
```

### ç±»å‹æ³¨è§£

æ‰€æœ‰æ–°ä»£ç éƒ½åº”è¯¥åŒ…å«ç±»å‹æ³¨è§£ï¼š

```python
from typing import List, Optional, Dict, Any
from dataclasses import dataclass

@dataclass
class ModelInfo:
    id: str
    name: str
    path: str
    model_type: ModelType
    size: int
    config: Dict[str, Any]

def load_model(model_path: str, config: Dict[str, Any]) -> Optional[Any]:
    """åŠ è½½æ¨¡å‹æ–‡ä»¶ã€‚
    
    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        config: æ¨¡å‹é…ç½®å‚æ•°
        
    Returns:
        åŠ è½½çš„æ¨¡å‹å¯¹è±¡ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    try:
        # å®ç°ä»£ç 
        return model
    except Exception as e:
        logger.error(f"Failed to load model: {e}")
        return None
```

### æ–‡æ¡£å­—ç¬¦ä¸²

ä½¿ç”¨Googleé£æ ¼çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼š

```python
def generate_stream(self, prompt: str, config: Dict[str, Any]) -> Iterator[str]:
    """ç”Ÿæˆæµå¼æ–‡æœ¬è¾“å‡ºã€‚
    
    Args:
        prompt: è¾“å…¥æç¤ºè¯
        config: ç”Ÿæˆé…ç½®å‚æ•°
        
    Yields:
        ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ
        
    Raises:
        ModelNotLoadedError: æ¨¡å‹æœªåŠ è½½æ—¶æŠ›å‡º
        InferenceError: æ¨ç†è¿‡ç¨‹å‡ºé”™æ—¶æŠ›å‡º
        
    Example:
        >>> inferencer = PyTorchInferencer()
        >>> inferencer.load_model("path/to/model", {})
        >>> for text in inferencer.generate_stream("Hello", {}):
        ...     print(text, end="")
    """
```

### é”™è¯¯å¤„ç†

ä½¿ç”¨è‡ªå®šä¹‰å¼‚å¸¸ç±»å’Œé€‚å½“çš„é”™è¯¯å¤„ç†ï¼š

```python
from multi_llm_comparator.core.exceptions import ModelNotFoundError, InferenceError

def load_model(self, model_path: str) -> None:
    """åŠ è½½æ¨¡å‹ã€‚"""
    if not os.path.exists(model_path):
        raise ModelNotFoundError(f"Model file not found: {model_path}")
    
    try:
        self.model = torch.load(model_path)
    except Exception as e:
        raise InferenceError(f"Failed to load model: {e}") from e
```

## æµ‹è¯•æŒ‡å—

### æµ‹è¯•ç»“æ„

```
tests/
â”œâ”€â”€ unit/                   # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_model_manager.py
â”‚   â”œâ”€â”€ test_inferencers.py
â”‚   â””â”€â”€ test_config.py
â”œâ”€â”€ integration/            # é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ test_inference_engine.py
â”‚   â””â”€â”€ test_ui_integration.py
â”œâ”€â”€ fixtures/               # æµ‹è¯•æ•°æ®
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ configs/
â””â”€â”€ conftest.py            # pytesté…ç½®
```

### ç¼–å†™æµ‹è¯•

```python
import pytest
from unittest.mock import Mock, patch
from multi_llm_comparator.services.model_manager import ModelManager

class TestModelManager:
    """æ¨¡å‹ç®¡ç†å™¨æµ‹è¯•ç±»ã€‚"""
    
    @pytest.fixture
    def model_manager(self):
        """åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨å®ä¾‹ã€‚"""
        return ModelManager()
    
    def test_scan_models_success(self, model_manager, tmp_path):
        """æµ‹è¯•æ¨¡å‹æ‰«ææˆåŠŸåœºæ™¯ã€‚"""
        # åˆ›å»ºæµ‹è¯•æ¨¡å‹æ–‡ä»¶
        model_file = tmp_path / "test_model.bin"
        model_file.write_text("fake model data")
        
        # æ‰§è¡Œæ‰«æ
        models = model_manager.scan_models(str(tmp_path))
        
        # éªŒè¯ç»“æœ
        assert len(models) == 1
        assert models[0].name == "test_model"
        assert models[0].model_type == ModelType.PYTORCH
    
    def test_scan_models_empty_directory(self, model_manager, tmp_path):
        """æµ‹è¯•ç©ºç›®å½•æ‰«æã€‚"""
        models = model_manager.scan_models(str(tmp_path))
        assert len(models) == 0
    
    @patch('torch.load')
    def test_load_model_failure(self, mock_torch_load, model_manager):
        """æµ‹è¯•æ¨¡å‹åŠ è½½å¤±è´¥ã€‚"""
        mock_torch_load.side_effect = RuntimeError("CUDA out of memory")
        
        with pytest.raises(InferenceError):
            model_manager.load_model("fake_path.bin", {})
```

### è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
uv run pytest

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
uv run pytest tests/unit/test_model_manager.py

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–¹æ³•
uv run pytest tests/unit/test_model_manager.py::TestModelManager::test_scan_models_success

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
uv run pytest --cov=src/multi_llm_comparator --cov-report=html

# è¿è¡Œæ€§èƒ½æµ‹è¯•
uv run pytest tests/performance/ -v
```

## æäº¤è§„èŒƒ

### æäº¤æ¶ˆæ¯æ ¼å¼

ä½¿ç”¨[Conventional Commits](https://www.conventionalcommits.org/)è§„èŒƒï¼š

```
<type>[optional scope]: <description>

[optional body]

[optional footer(s)]
```

### æäº¤ç±»å‹

- `feat`: æ–°åŠŸèƒ½
- `fix`: ä¿®å¤bug
- `docs`: æ–‡æ¡£æ›´æ–°
- `style`: ä»£ç æ ¼å¼åŒ–ï¼ˆä¸å½±å“åŠŸèƒ½ï¼‰
- `refactor`: ä»£ç é‡æ„
- `test`: æ·»åŠ æˆ–ä¿®æ”¹æµ‹è¯•
- `chore`: æ„å»ºè¿‡ç¨‹æˆ–è¾…åŠ©å·¥å…·çš„å˜åŠ¨

### ç¤ºä¾‹

```bash
# æ–°åŠŸèƒ½
git commit -m "feat(inference): add GGUF model support"

# ä¿®å¤bug
git commit -m "fix(ui): resolve memory leak in model display"

# æ–‡æ¡£æ›´æ–°
git commit -m "docs: update installation guide for Windows"

# é‡æ„
git commit -m "refactor(core): simplify model loading logic"
```

## Pull RequestæŒ‡å—

### PRæ ‡é¢˜

ä½¿ç”¨ä¸æäº¤æ¶ˆæ¯ç›¸åŒçš„æ ¼å¼ï¼š
```
feat(inference): add streaming output support
```

### PRæè¿°æ¨¡æ¿

```markdown
## å˜æ›´ç±»å‹
- [ ] æ–°åŠŸèƒ½
- [ ] Bugä¿®å¤
- [ ] æ–‡æ¡£æ›´æ–°
- [ ] ä»£ç é‡æ„
- [ ] æ€§èƒ½ä¼˜åŒ–

## å˜æ›´æè¿°
ç®€è¦æè¿°æ­¤PRçš„å˜æ›´å†…å®¹ã€‚

## æµ‹è¯•
- [ ] æ·»åŠ äº†æ–°çš„æµ‹è¯•ç”¨ä¾‹
- [ ] æ‰€æœ‰ç°æœ‰æµ‹è¯•é€šè¿‡
- [ ] æ‰‹åŠ¨æµ‹è¯•é€šè¿‡

## æ£€æŸ¥æ¸…å•
- [ ] ä»£ç éµå¾ªé¡¹ç›®è§„èŒƒ
- [ ] æ·»åŠ äº†å¿…è¦çš„æ–‡æ¡£
- [ ] æ›´æ–°äº†CHANGELOG.md
- [ ] æ²¡æœ‰å¼•å…¥ç ´åæ€§å˜æ›´

## ç›¸å…³Issue
Closes #123
```

### ä»£ç å®¡æŸ¥

æ‰€æœ‰PRéƒ½éœ€è¦ç»è¿‡ä»£ç å®¡æŸ¥ï¼š

1. **è‡ªæˆ‘å®¡æŸ¥**ï¼šæäº¤å‰ä»”ç»†æ£€æŸ¥ä»£ç 
2. **åŒè¡Œå®¡æŸ¥**ï¼šè‡³å°‘ä¸€ä¸ªç»´æŠ¤è€…çš„æ‰¹å‡†
3. **è‡ªåŠ¨æ£€æŸ¥**ï¼šé€šè¿‡æ‰€æœ‰CIæ£€æŸ¥

## å‘å¸ƒæµç¨‹

### ç‰ˆæœ¬å·è§„èŒƒ

ä½¿ç”¨[è¯­ä¹‰åŒ–ç‰ˆæœ¬](https://semver.org/)ï¼š
- `MAJOR.MINOR.PATCH`
- ä¾‹å¦‚ï¼š`1.2.3`

### å‘å¸ƒæ­¥éª¤

1. **æ›´æ–°ç‰ˆæœ¬å·**
```bash
# æ›´æ–°pyproject.tomlä¸­çš„ç‰ˆæœ¬å·
version = "1.2.3"
```

2. **æ›´æ–°CHANGELOG**
```markdown
## [1.2.3] - 2024-01-15

### Added
- æ–°å¢GGUFæ¨¡å‹æ”¯æŒ

### Fixed
- ä¿®å¤å†…å­˜æ³„æ¼é—®é¢˜

### Changed
- ä¼˜åŒ–æ¨¡å‹åŠ è½½æ€§èƒ½
```

3. **åˆ›å»ºå‘å¸ƒæ ‡ç­¾**
```bash
git tag -a v1.2.3 -m "Release version 1.2.3"
git push origin v1.2.3
```

## ç¤¾åŒºå‚ä¸

### æŠ¥å‘Šé—®é¢˜

ä½¿ç”¨GitHub IssuesæŠ¥å‘Šbugæˆ–è¯·æ±‚åŠŸèƒ½ï¼š

1. æœç´¢ç°æœ‰Issuesé¿å…é‡å¤
2. ä½¿ç”¨é€‚å½“çš„Issueæ¨¡æ¿
3. æä¾›è¯¦ç»†çš„å¤ç°æ­¥éª¤
4. åŒ…å«ç³»ç»Ÿç¯å¢ƒä¿¡æ¯

### å‚ä¸è®¨è®º

- GitHub Discussionsï¼šé¡¹ç›®ç›¸å…³è®¨è®º
- Code Reviewï¼šå‚ä¸ä»£ç å®¡æŸ¥
- Documentationï¼šæ”¹è¿›æ–‡æ¡£

### è¡Œä¸ºå‡†åˆ™

è¯·éµå¾ªæˆ‘ä»¬çš„[è¡Œä¸ºå‡†åˆ™](CODE_OF_CONDUCT.md)ï¼Œè¥é€ å‹å¥½çš„ç¤¾åŒºç¯å¢ƒã€‚

## èµ„æºé“¾æ¥

- [é¡¹ç›®ä¸»é¡µ](https://github.com/your-org/multi-llm-comparator)
- [é—®é¢˜è·Ÿè¸ª](https://github.com/your-org/multi-llm-comparator/issues)
- [è®¨è®ºåŒº](https://github.com/your-org/multi-llm-comparator/discussions)
- [Wiki](https://github.com/your-org/multi-llm-comparator/wiki)

æ„Ÿè°¢æ‚¨çš„è´¡çŒ®ï¼ğŸ‰